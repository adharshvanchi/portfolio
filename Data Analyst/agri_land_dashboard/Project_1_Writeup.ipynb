{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Agricultural Land Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Objective:\n",
    "Investigate the relationship between agricultural cropland value and crop yield. The target audience or stakeholders for this project are prospective crop land investors looking to choose the best state to invest in crop land. Some of the questions I wanted to investigate include: What are the states with high crop yield to acre value ratios? What are the trends in both key metrics over time? Which States and Regions had the highest Acre Values, Crop Yields and Crop Yield to Acre Value Ratios? I also wanted a map of the states with a gradient of Acre Value and Crop Yield to get an intuitive visual of the patterns. Acre Value, gathered from Kaggle.com, does not contain most of New England as these states weren't in the dataset. Crop Yield was gathered from USDA's National Agricultural Statistics Service(NASS) Quick Stats, which is their self service data mart. The time frame of the data is from 2007-2017.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acre Value\n",
    "I am the most comfortable working with python, so that's where I began. I used it to ingest the downloaded data, clean it, and load it into the SQL server. The first thing I did was download the Acre Value data from Kaggle and the Crop Yield data from USDA's NASS Quick Stats, both as csv files. After importing the necessary libraries, I ingested the csv data into a DataFrame, removed unnecessary rows and columns, removed any NA/Null values and reset the index for the next steps for the three Acre Value data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region and state</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Northeast</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>2690.0</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>4320</td>\n",
       "      <td>4970</td>\n",
       "      <td>5350</td>\n",
       "      <td>5590</td>\n",
       "      <td>5340</td>\n",
       "      <td>5270</td>\n",
       "      <td>5200</td>\n",
       "      <td>5280</td>\n",
       "      <td>5260</td>\n",
       "      <td>5260</td>\n",
       "      <td>5330</td>\n",
       "      <td>5390</td>\n",
       "      <td>5350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3850.0</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>8100</td>\n",
       "      <td>10000</td>\n",
       "      <td>10200</td>\n",
       "      <td>9800</td>\n",
       "      <td>8500</td>\n",
       "      <td>7930</td>\n",
       "      <td>7840</td>\n",
       "      <td>7850</td>\n",
       "      <td>7870</td>\n",
       "      <td>7880</td>\n",
       "      <td>7950</td>\n",
       "      <td>8200</td>\n",
       "      <td>8100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>8200</td>\n",
       "      <td>8400</td>\n",
       "      <td>7800</td>\n",
       "      <td>7300</td>\n",
       "      <td>6790</td>\n",
       "      <td>6680</td>\n",
       "      <td>6570</td>\n",
       "      <td>6470</td>\n",
       "      <td>6470</td>\n",
       "      <td>6470</td>\n",
       "      <td>6530</td>\n",
       "      <td>6530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>8700.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>13000</td>\n",
       "      <td>14900</td>\n",
       "      <td>16000</td>\n",
       "      <td>15600</td>\n",
       "      <td>14000</td>\n",
       "      <td>13300</td>\n",
       "      <td>12900</td>\n",
       "      <td>12400</td>\n",
       "      <td>12900</td>\n",
       "      <td>13000</td>\n",
       "      <td>13500</td>\n",
       "      <td>13000</td>\n",
       "      <td>13000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region and state    1997    1998    1999    2000    2001    2002    2003  \\\n",
       "0        Northeast  2590.0  2620.0  2700.0  2690.0  2820.0  3210.0  3400.0   \n",
       "1         Delaware  2500.0  2620.0  2700.0  3000.0  3250.0  3500.0  3850.0   \n",
       "2         Maryland  3050.0  3100.0  3200.0  3500.0  3700.0  3900.0  4000.0   \n",
       "3       New Jersey  8500.0  8000.0  7800.0  8400.0  8700.0  9000.0  9300.0   \n",
       "\n",
       "     2004   2005   2006   2007   2008   2009   2010   2011   2012   2013  \\\n",
       "0  3800.0   4320   4970   5350   5590   5340   5270   5200   5280   5260   \n",
       "1  5700.0   8100  10000  10200   9800   8500   7930   7840   7850   7870   \n",
       "2  5600.0   7200   8200   8400   7800   7300   6790   6680   6570   6470   \n",
       "3  9900.0  13000  14900  16000  15600  14000  13300  12900  12400  12900   \n",
       "\n",
       "    2014   2015   2016   2017  \n",
       "0   5260   5330   5390   5350  \n",
       "1   7880   7950   8200   8100  \n",
       "2   6470   6470   6530   6530  \n",
       "3  13000  13500  13000  13000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sqlalchemy import *\n",
    "\n",
    "# Constant of Region Names\n",
    "REGIONS= (\"Northeast\", \"Lake\", \"Corn Belt\", \"Northern Plains\", \"Appalachian\", \"Southeast\", \"Delta\", \"Southern Plains\", \"Mountain\", \"Pacific\")\n",
    "\n",
    "# Pull in cropland data \n",
    "cropland_df = pd.read_csv('data\\Combined Data - Cropland.csv', header = 4)\n",
    "# Remove junk columns\n",
    "cropland_df.drop(columns = ['2','h','2016-2017'],index=[0,1],inplace=True)\n",
    "# Remove random characters\n",
    "cropland_df.replace('[1234567890]/', '', regex=True,inplace=True)\n",
    "# Drop NA values and reset index\n",
    "cropland_df.dropna(inplace=True)\n",
    "cropland_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "cropland_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the data format showed that it needs to be melted such that each row contains the state, region, year, and acre value. So, next I extracted the indices of all rows with a region instead of a state along with the last row and assigned them to a list to do the melt mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 7, 11, 17, 22, 28, 33, 37, 40, 49, 54]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the rows for each region\n",
    "cropland_reg = cropland_df[cropland_df['Region and state'].isin(REGIONS)]\n",
    "\n",
    "# Make a list of the indices of each region's row\n",
    "cropland_list = list(cropland_reg.index)\n",
    "\n",
    "# Append the last row of each dataframe\n",
    "cropland_list.append(cropland_df.shape[0])\n",
    "\n",
    "cropland_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the list of indices, I created a dictionary of each region name along with the first and last state's index in that region. (i.e. cropland_df contains 'Northeast' states in indices 1 through 7.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Northeast': [1, 7],\n",
       " 'Lake': [8, 11],\n",
       " 'Corn Belt': [12, 17],\n",
       " 'Northern Plains': [18, 22],\n",
       " 'Appalachian': [23, 28],\n",
       " 'Southeast': [29, 33],\n",
       " 'Delta': [34, 37],\n",
       " 'Southern Plains': [38, 40],\n",
       " 'Mountain': [41, 49],\n",
       " 'Pacific': [50, 54]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate index dictionaries for each dataframe\n",
    "cropland_idx_dict = {}\n",
    "\n",
    "# For the each element of cropland_list, create a new entry in the index dictionary with the first and last index of that region's states (i.e. 'Northeast': [1, 7])\n",
    "for i in range(0,len(cropland_list)-1):\n",
    "  cropland_idx_dict[REGIONS[i]] = [cropland_list[i]+1,cropland_list[i+1]]\n",
    "\n",
    "cropland_idx_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renamed the \"Region and state\" column to \"State\" and created a new column called \"Region\". Iterated through the index dictionary's keys, which are region names, created in the previous block to assign the 'Region' value to all the rows, then dropped all rows with index in region index list so the remaining rows only have state names in newly renamed \"State\" column. Finally, I dropped the last row in each table, which had the US cumulative data and reset the indices. This process was completed for each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Region and state' column to 'State' and create new 'Region' Column\n",
    "cropland_df.rename(columns={'Region and state':'State'},inplace=True)\n",
    "cropland_df['Region'] = ''\n",
    "# for each region, assign the region's name to 'Region' Column\n",
    "for i in cropland_idx_dict.keys():\n",
    "  cropland_df.loc[cropland_idx_dict[i][0]:cropland_idx_dict[i][1], 'Region'] = i\n",
    "# Drop all rows that contain the regional data\n",
    "cropland_df.drop(index=cropland_list[:-1],inplace=True)\n",
    "# Drop row that contains cumulative US data and reset index\n",
    "cropland_df.drop(index=[53],inplace=True)\n",
    "cropland_df.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melted the DataFrames so that the State and Region columns remain untouched, and each row only has one Acre Value and a corresponding year. (i.e. \"California\", \"Pacific\", \"2017\", \"2700.0\"). Then cleaned up the DataFrame (forcing Acre Value to be a numeric, and dropping any NA values), added Land Use column and reset index one final time for each dataframe. Finally, all three dataframes are concatenated into \"df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt dataframe so each row only has one year and one acre value, convert acre value to numeric, and drop all NAs\n",
    "cropland = pd.melt(cropland_df,id_vars=['State','Region'],var_name='Year',value_name='Acre Value')\n",
    "cropland['Acre Value'] = pd.to_numeric(cropland['Acre Value'],errors='coerce')\n",
    "cropland.dropna(inplace=True)\n",
    "# Assign Land use as Cropland and reset index\n",
    "cropland['Land Use'] = 'Cropland'\n",
    "cropland.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last python step for Acre Value was to establish an ODBC connection to the SQL server on my local machine ('ADHARSHVANCHI-P'), and using the pandas `to_sql` function to load the data into its table. Just as a check, I run a quick query to trim any whitespaces at the beginning or end of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize SQL Connection\n",
    "metadata = MetaData()\n",
    "engine = create_engine(\"mssql+pyodbc://ADHARSHVANCHI-P/Agricultural_Land_Data?driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "\n",
    "# Load final table into SQL as agricultural_landvalue\n",
    "cropland.to_sql('agricultural_landvalue',con=engine,if_exists='replace',index=False)\n",
    "\n",
    "# Update table by removing leading and trailing whitespaces\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"UPDATE agricultural_landvalue SET state = TRIM(state)\"))\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Yield\n",
    "For Crop Yield, I ingested the data, filtered only for the columns that are relevant to my analysis, dropped any NA/Null values, reset the index, renamed the 'Value' column to 'Crop Yield' for ease of use, converted the all upper case state names (i.e. 'NEVADA') to match the title case of the Acre Value dataset (i.e. 'Nevada') and loaded the data into SQL with the same method as the Acre Value dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropprod_df = pd.read_csv('data\\Crop Production in $.csv')\n",
    "cropprod_df = cropprod_df[['Year','State','Value']]\n",
    "cropprod_df.dropna(inplace=True)\n",
    "cropprod_df.reset_index(drop=True,inplace=True)\n",
    "cropprod_df.rename(columns={'Value':'Crop Yield'},inplace=True)\n",
    "cropprod_df['State'] = cropprod_df['State'].apply(str.title)\n",
    "cropprod_df.to_sql('crop_production',con=engine,if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Component\n",
    "Once both Datasets were loaded into the Database \"Agricultural Land Value\", I created a new view named \"VW_Ag_Land\" which joined agricultural_landvalue and crop_production on columns year and state. This view is what was pulled into PowerBI to create the visuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PowerBI Visualization Explanations\n",
    "[Link to PowerBI Report to Follow Along](https://app.powerbi.com/view?r=eyJrIjoiZmZjNzM2ZDQtYjA4OC00YzY4LWI1ZGQtNThmMWQyOTE5NTFjIiwidCI6ImJhNTkzNWM2LTI5OTQtNGJhZS1hYzJhLTAyMGI5N2IyNTczNCIsImMiOjJ9&pageName=5a514db2ffde38ce2746)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 1: Overview\n",
    "This page shows all the available data as a scatterplot with Acre Value on the x-axis and Crop Yield on the y-axis. On the right side, there are slicers to filter states and years. Looking at the visual, we can see that California is notably higher in both Crop yield and Acre Value. Conversely, New Jersey has very high acre values for very low crop yields, making it a poor investment candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 2: Crop Yield to Acre Value Ratio Bar Graph\n",
    "This visual is to rank the states by Acre Value, Crop Yield and Crop Yield to Acre Value Ratio. The top three candidate states I would recommend based on the insights on the third graph would be North Dakota, Texas and Kansas as these states have the highest crop yield to acre value ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 3: Value and Yield over Time by Region\n",
    "The top graph shows Average Acre Value over Time. As the first page indicated, New Jersey is the highest valued throught the entire time frame. Hovering over the graph shows a table of the top 5 states by Average Acre Value for that given year. \n",
    "\n",
    "The middle graph shows crop value over time. Here we see Calidfornia along with many of the bread basket states, which is to be expected. Hovering here shows a similar custom tooltip, but with Average Crop Yield. \n",
    "\n",
    "The bottom graph shows Crop Yield/Acre Value as a ratio to determine, on average, which states have the highest return on land value. Surprisingly to me, North Dakota led the pack from 2007-2013, and continued to be top three for the remainder of the time frame. This graph is the most useful in determining what states to consider for cropland investment. Looking at the states I recommend based on the bar graph, we see that all three of them have been in the top 5 over the entire timeframe of the dataset.\n",
    "\n",
    "The States Slicer on the right lets users compare their selection of states over the timeframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 4: Map of Crop Yield to Acre Value Ratio\n",
    "\n",
    "This map visualizes the geographic distribution of the Crop Yield to Acre Value ratio with a year slicer to tunnel down in user specified time windows. As noted in the project overview, most of New England is not part of the dataset, as visible here.\n",
    "\n",
    "![](misc/pbi_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers to Questions from Project Overview\n",
    "What are the trends in both key metrics over time? \n",
    "\n",
    "Removing California and New Jersey from the visuals on Page 2 shows that Crop Yield is generally stable while Acre Value is slightly increasing over time.\n",
    "\n",
    "Which States and Regions had the highest Acre Values, Crop Yields and Crop Yield to Acre Value Ratios? \n",
    "\n",
    "Acre Value:\n",
    "1. New Jersey\n",
    "2. California\n",
    "3. Arizona\n",
    "\n",
    "Crop Yield:\n",
    "1. California\n",
    "2. Iowa\n",
    "3. Illinois\n",
    "\n",
    "Crop Yield to Acre Value:\n",
    "1. North Dakota\n",
    "2. Kansas\n",
    "3. Texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
